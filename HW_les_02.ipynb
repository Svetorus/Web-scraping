{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW les 02.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panzershracker/Web-scraping/blob/master/HW_les_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuTKsOE7no-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests, re\n",
        "from pprint import pprint\n",
        "from collections import Counter as counter\n",
        "from bs4 import BeautifulSoup as bs4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Bv6gaBohkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://ru.wikipedia.org/wiki/'\n",
        "\n",
        "target = 'дерево'.capitalize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th9l-O6mqknM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "038ce7cd-6013-4eb6-d474-1211b439c314"
      },
      "source": [
        "r = requests.get(url+target)\n",
        "\n",
        "print(r.encoding)\n",
        "\n",
        "soup = bs4(r.text, 'html.parser')\n",
        "\n",
        "head = soup.h1.next.strip()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UTF-8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5ipAzMkqthc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "be31e3d3-813e-441f-e19a-26c2527b7392"
      },
      "source": [
        "print(r.status_code)\n",
        "print(f'Тема: {head}')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "Тема: Дерево\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjL2Js0vqsUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# находим необходимые элементы для парсинга по тегам и переводим все в строковый формат\n",
        "main_text = str(soup.find_all(['p', 'li', 'span', 'a']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwqB8WGzEmA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae0ef827-5dfb-4a1e-9c9a-c3c6402572f7"
      },
      "source": [
        "mask = '[а-яА-Я]{4,}'\n",
        "\n",
        "# создаем обьект counter на на основе маски и текста из супа по ключевым тегам\n",
        "words = counter(re.findall(mask, main_text))\n",
        "\n",
        "print(len(words))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg7oxELaFsWH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "4ecc2e63-19e4-49e8-83c2-098801e889f0"
      },
      "source": [
        "# Наиболее частые слова на основной странице\n",
        "for i in words.most_common(20):\n",
        "  print(i)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Редактировать', 79)\n",
            "('раздел', 76)\n",
            "('править', 76)\n",
            "('язык', 60)\n",
            "('Латинский', 56)\n",
            "('деревьев', 55)\n",
            "('деревья', 55)\n",
            "('Дерево', 52)\n",
            "('дерево', 39)\n",
            "('Розовые', 36)\n",
            "('растений', 35)\n",
            "('страница', 32)\n",
            "('дерева', 30)\n",
            "('видов', 30)\n",
            "('Сосновые', 30)\n",
            "('Слива', 30)\n",
            "('Кипарисовые', 27)\n",
            "('отсутствует', 27)\n",
            "('Википедия', 26)\n",
            "('семейства', 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdnZmC_1mlG9",
        "colab_type": "text"
      },
      "source": [
        "# !\n",
        "#### Не знал как сделать дальше чтоб было красиво, поэтому применил фильтр startswith. Если будут рекомендации, как методами СУПА чисто вытащить ссылку (с уточнением класса, например) - буду рад услышать."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HvpMzbrFtIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "020f9acb-402d-48b2-a15e-c5c4bf2536f6"
      },
      "source": [
        "# Получаем из обьекта супа необходимые нам теги для парсинга. Используем css селектор\n",
        "\n",
        "links_raw = soup.select('#mw-content-text > div > ul > li > a')\n",
        "\n",
        "links = []\n",
        "\n",
        "# используем фильтр .startswith для выбора целевых ссылок\n",
        "for i in links_raw:\n",
        "  if i.get('href').startswith('http'):\n",
        "    links.append(i.get('href'))\n",
        "    \n",
        "pprint(links)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['http://transspot.ru/2013/05/31/pro-derevya-na-ulicax/',\n",
            " 'http://ec-dejavu.ru/d/Derevo.html',\n",
            " 'http://www.maleus.ru/index.php/news/129-tree',\n",
            " 'http://www.na.fs.fed.us/spfo/pubs/silvics_manual/table_of_contents.htm',\n",
            " 'http://hort.ifas.ufl.edu/woody/']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRa7hqXB2mnh",
        "colab_type": "text"
      },
      "source": [
        "### Запилил весь парсинг по сторонним сайтам в одну комплексную функцию. Не красиво, моветон - зато быстро )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6diogW5ni5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def links_pars(links, mask, count):\n",
        "  # Функция парсинга сторонних сайтов из раздела \"ссылки\"\n",
        "  # Аргументы: список ссылок, маска поиска, кол-во наиболее встречаемых слов\n",
        "  \n",
        "  # перебор по ссылкам из списка (из раздела \"Ссылки\")\n",
        "  for link in links:\n",
        "    \n",
        "    r = requests.get(link)\n",
        "    \n",
        "    # меняем кодировку:\n",
        "    r.encoding = r.apparent_encoding\n",
        "    \n",
        "    # создаем обьект супа\n",
        "    soup = bs4(r.text, 'html.parser')\n",
        "    \n",
        "    # создаем счетчик(из модуля collections) на базе текста страницы\n",
        "    words = counter(re.findall(mask, str(soup)))\n",
        "    \n",
        "    # Условие: если список слов пустой - меняем маску поиска regex на английскую\n",
        "    if len(words) == 0:\n",
        "      \n",
        "      en_mask = '[a-zA-Z]{4,}'\n",
        "      words = counter(re.findall(en_mask, str(soup)))\n",
        "    \n",
        "    # Выводим код ответа, адрес ресурса и наиболее встречаемые слова\n",
        "    print(f' Status code for {link} is: {r.status_code}\\n'\n",
        "          f' Наиболее часто встречаемые слова в документе:\\n {words.most_common(count)}\\n'\n",
        "          f'==================================================================================')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeemTGLmolex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "46072343-4c1e-4e60-fde7-8e099721b7bf"
      },
      "source": [
        "links_pars(links, mask, 5)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Status code for http://transspot.ru/2013/05/31/pro-derevya-na-ulicax/ is: 200\n",
            " Наиболее часто встречаемые слова в документе:\n",
            " [('движения', 26), ('деревьев', 25), ('деревья', 19), ('городе', 17), ('Деревья', 16)]\n",
            "==================================================================================\n",
            " Status code for http://ec-dejavu.ru/d/Derevo.html is: 200\n",
            " Наиболее часто встречаемые слова в документе:\n",
            " [('Гваттари', 33), ('дерево', 26), ('дерева', 20), ('Делез', 16), ('мира', 14)]\n",
            "==================================================================================\n",
            " Status code for http://www.maleus.ru/index.php/news/129-tree is: 200\n",
            " Наиболее часто встречаемые слова в документе:\n",
            " [('окаменелости', 4), ('Сбор', 4), ('средств', 4), ('хостинг', 4), ('дизайн', 4)]\n",
            "==================================================================================\n",
            " Status code for http://www.na.fs.fed.us/spfo/pubs/silvics_manual/table_of_contents.htm is: 200\n",
            " Наиболее часто встречаемые слова в документе:\n",
            " [('class', 438), ('data', 358), ('naspf', 189), ('href', 149), ('https', 108)]\n",
            "==================================================================================\n",
            " Status code for http://hort.ifas.ufl.edu/woody/ is: 200\n",
            " Наиболее часто встречаемые слова в документе:\n",
            " [('href', 50), ('shtml', 42), ('class', 18), ('http', 12), ('style', 10)]\n",
            "==================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE2UOysF2NWJ",
        "colab_type": "text"
      },
      "source": [
        "#!\n",
        "#### Так как две последние ссылки ведут не на статьи а на полу пустые страницы - в них преобладают слова из кода, т.к. они составляют большинство встречающихся слов."
      ]
    }
  ]
}